{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Space Omid Documentation","text":"<p>Description and feature list of projects. sample data.</p>"},{"location":"#projects","title":"Projects","text":"<ul> <li><code>Image Processing Platform</code> - PLatform for manage Map tile and ...</li> <li><code>Drone</code> - Spraying farming land via drone and ...</li> <li><code>Farming</code> - Mange farming operation like ...</li> <li><code>Satellite Communicator</code> - Satellite based social network.</li> <li><code>Satellite Data Collector</code> - Farming data collector via satellite communication.</li> <li><code>Mission Design</code> - Designing the mission of system satellites.</li> <li><code>HODHOD GS</code> - HodHod satellite ground station.</li> </ul>"},{"location":"#system-arch","title":"System Arch.","text":"<p>Diagram of System Architecture</p>"},{"location":"#developers","title":"Developers","text":"<ul> <li>Mr. TalebElm</li> <li>Mr. Yaghini</li> <li>Mr. Zarei</li> <li>Ms. Sabahi</li> </ul>"},{"location":"Arch/","title":"Project Architecture","text":"<pre><code>flowchart TB\n\n    classDef Elk fill:#d500f933;\n\n    style Gateway fill:#00c85333\n    style Streaming fill:#448aff,stroke-width:4px,color:#fff\n    style Streaming_ fill:#448aff,stroke-width:4px,color:#fff\n\n    subgraph Internet\n\n    subgraph Web\n    Map\n    DataGatheringDashboard[Data Gathering Dashboard]\n    end\n\n    subgraph Mobile\n    Drone\n    MessengerApp\n    end\n\n    end\n\n    subgraph Firewall\n    Gateway\n    end\n\n    subgraph WIFI_ReceiverTransceiver[WIFI and Receiver Transceiver]\n    subgraph Hardware\n    subgraph Modem\n    DataGatheringHW\n    MessengerHW\n    end\n    end\n    end\n\n    subgraph Satellite\n        SatelliteHardware[Satellite Hardware]\n    end\n\n    WIFI_ReceiverTransceiver --RADIO--&gt; Satellite\n    Satellite --RADIO--&gt; HodhodServer\n\n    Internet --REST--&gt; WIFI_ReceiverTransceiver\n\n    Internet --REST--&gt; Gateway\n\n    Gateway --REST--&gt; Financial\n    Gateway --REST--&gt; DroneBackend[Drone Backend]\n    Gateway --REST--&gt; MapDataHandler[Map Data Handler] \n\n    Gateway --REST--&gt; HodhodServer[Hodhod Server]\n    Gateway --REST--&gt; MessageSender[Message Sender]   \n\n    MapDataHandler --&gt; ELKHandler[(ELK Handler)]:::Elk\n    MapDataHandler --RabbitMQ--&gt; OSE[Omid Space Engine ]\n    MapDataHandler --RabbitMQ--&gt; GEE[Google Earth Engine ]\n    MapDataHandler --RabbitMQ--&gt; TPE[Third Party Engine ]\n    MapDataHandler --RabbitMQ--&gt; Publisher[Publisher]\n    Publisher --ws--&gt; Streaming_\n    Streaming --ws--&gt; Internet\n\n    HodhodServer --REST--&gt; ELKHodhod[(ELK Hodhod)]\n    MessageSender --REST--&gt; ELKSmsEmail[(ELK Sms Email)]\n\n    DroneBackend --REST--&gt; ELKDrone[(ELK Drone)]:::Elk\n\n    subgraph G.E.E.\n    GEE\n    Google\n    BucketGEE\n    ELKGEE\n    end\n\n    GEE --GRPC--&gt; Google([Google])\n    GEE --&gt; ELKGEE[(ELK GEE)]:::Elk\n    GEE --&gt; BucketGEE[(Bucket GEE)]\n\n\n    subgraph O.S.E.\n    OSE\n    end\n\n</code></pre> <pre><code>flowchart LR\n\n    subgraph Presentation_Layer[Presentation Layer]\n        subgraph Web\n            Map\n            DataGatheringDashboard[Data Gathering Dashboard]\n        end\n        subgraph Mobile\n            Drone\n            MessengerApp\n        end\n    end\n\n    subgraph Domain_Layer[Domain Layer]\n        style ELK fill:#d500f933;\n        style ELKDrone fill:#d500f933;\n        style ELKHodhod fill:#d500f933;\n        style ELKSmsEmail fill:#d500f933;\n        style ELKGEE fill:#d500f933;\n        style ELKHodhod fill:#d500f933;\n        style ELKDrone fill:#d500f933;\n        style ELKFinancial fill:#d500f933;\n        style ELKSOE fill:#d500f933;\n        style BucketGEE fill:#00c85333\n        style BucketSOE fill:#00c85333\n        ELKHodhod[(ELK Hodhod)]\n        BucketGEE[(Bucket GEE)]\n        ELKGEE[(ELK GEE)]\n        BucketSOE[(Bucket SOE)]\n        ELKSOE[(ELK SOE)]\n        ELK[(ELK Handler)]\n        ELKFinancial[(ELK Financial)]\n        ELKDrone[(ELK Drone)]\n        ELKSmsEmail[(ELK Sms Email)]\n    end\n\n    Presentation_Layer -- REST --&gt; Internet\n\n    subgraph Application_Services_Layer[Application Services Layer]\n        style Gateway fill:#00c85333\n        style OSE fill:#00c85333\n        style Financial fill:#00c85333\n        style DroneBackend fill:#00c85333\n        style MapDataHandler fill:#00c85333\n        style HodhodServer fill:#00c85333\n        style MessageSender fill:#00c85333\n        style GEE fill:#00c85333\n        MapDataHandler --RabbitMQ--&gt; OSE[Space Omid Engine ]\n        MapDataHandler --RabbitMQ--&gt; GEE[Google Earth Engine ]\n        MapDataHandler --RabbitMQ--&gt; TPE[Third Party Engine ]\n        GEE --&gt; BucketGEE[(Bucket GEE)]\n        OSE[Space Omid Engine ] --REST--&gt; ELKSOE[(ELK SOE)]\n        OSE --&gt; BucketSOE[(Bucket SOE)]\n        Gateway -- REST --&gt; Financial\n        Gateway -- REST --&gt; DroneBackend[Drone Backend]\n        Gateway -- REST --&gt; MapDataHandler[Map Data Handler] \n        Gateway -- REST --&gt; HodhodServer[Hodhod Server]\n        Gateway -- REST --&gt; MessageSender[Message Sender]   \n    end\n\n    subgraph Infrastructure_Layer[Infrastructure Layer]\n        style WIFI_ReceiverTransceiver fill:#00c85333\n        subgraph WIFI_ReceiverTransceiver[WIFI and Receiver Transceiver]\n        subgraph Modem\n        DataGatheringHW\n        MessengerHW\n        end\n        end\n        style Modem fill:#00c85333\n        style DataGatheringHW fill:#00c85333\n        style MessengerHW fill:#00c85333\n        style Satellite fill:#00c85333\n        style Google fill:#00c85333\n        WIFI_ReceiverTransceiver -- RADIO --&gt; Satellite\n        Satellite -- RADIO --&gt; HodhodServer\n        Internet -- REST --&gt; WIFI_ReceiverTransceiver\n        Internet -- REST --&gt; Gateway\n        MapDataHandler --REST--&gt; ELK[(ELK Handler)]\n        HodhodServer --REST--&gt; ELKHodhod[(ELK Hodhod)]\n        Financial --REST--&gt; ELKFinancial[(ELK Financial)]\n        MapDataHandler --RabbitMQ--&gt; Publisher[Publisher]\n        Publisher --ws--&gt; Streaming_\n        Streaming --ws--&gt; Internet\n        MessageSender --REST--&gt; ELKSmsEmail[(ELK Sms Email)]\n        DroneBackend --REST--&gt; ELKDrone[(ELK Drone)]\n        GEE --GRPC--&gt; Google([Google])\n        GEE --REST--&gt; ELKGEE[(ELK GEE)]\n    end</code></pre> <p>Gateway Financial \u0650Drone Message Sender</p>"},{"location":"API%20Structure/Description/","title":"Description","text":"<p>Structure</p> <p><pre><code>    // JSON\n{\n\"validationMessage\": [{\"stateCode\":200,\"message\":\"\"}]\n\"result\": \"AnyType\",\n\"resultStatus\": true\n}\n</code></pre> <pre><code>    // C# code\npublic class APIResult&lt;T&gt;\n{\npublic EResultStatus ResultStatus { get; set; } = EResultStatus.SUCCESS;\n\npublic T? Result { get; set; }\n\npublic List&lt;APIResultMessage&gt; APIResultMessages { get; set; } = new() { };\n}\n\npublic class APIResultMessage\n{\npublic int StateCode { get; set; } = 400;\npublic string Message { get; set; } = string.Empty;\n}\n\npublic enum EResultStatus\n{\nSUCCESS,\nFAILED\n}\n</code></pre></p>"},{"location":"Chatbot/","title":"Chatbot documentation","text":"<p>This documentation provides information about Chatbot project that its goal is to provide human like conversation and suggestion with users. right now it is using GPT but its not limited to. </p>"},{"location":"Chatbot/#technologies-used-in-project","title":"Technologies Used in Project","text":"<ul> <li>FastAPI</li> <li>ElasticSearch</li> <li>openai</li> </ul>"},{"location":"Chatbot/#getting-started","title":"Getting Started","text":"<p>In order to run the service in local mode use <code>uvicorn main:app --reload</code> command. the project has docker file that uses gunicorn with uvicorn worker</p>"},{"location":"Chatbot/#general-workflow-of-the-project","title":"General WorkFLow of the Project","text":"<ul> <li>There are one api references that can be used to ask question(ask question with json and get response as json)   </li> </ul>"},{"location":"Chatbot/#project-structure-and-workflow","title":"Project Structure and WorkFlow","text":"<p>first we talk about Util and Models folders and then about files in root directory of the project: Util This folder contains <code>elastic_connection.py</code> file with has the credentials of elastic * Models This part contains <code>chat_model.py</code> and <code>elastic_crud.py</code> files: chat_model.py this module defines a ChatInfo Pydantic model with two fields, user_id and prompt. It also defines a Chat_Model class with an initializer that takes in three arguments: user_id, prompt, and date_time.  </p> <p>The document method of the Chat_Model class returns a dictionary containing the values of the user_id, prompt, and date_time attributes.  </p> <p>this code creates a data structure to represent chats in chat application. The ChatInfo model is used to validate input data before creating a new chat instance using the Chat_Model class. The document method is used for serializing the chat object into a dictionary that can be stored in elastic and also can be transmitted over a network.   elastic_crud.py* This code defines an ElasticManager class that provides methods to interact with Elasticsearch. The initializer establishes a connection to Elasticsearch and prints a message to indicate successful connection.  </p> <p>The <code>insert</code> method takes in user_id, prompt, and date_time parameters and creates a new document using the Chat_Model class. The document method of the Chat_Model class is called to serialize the chat object into a dictionary that can be passed to the index method of the Elasticsearch client to store the document in an index. The index name can be overridden by passing the index parameter to the method. The method returns the result of the indexing operation.  </p> <p>The <code>search</code> method takes in a query parameter as a dictionary and performs a search operation on the specified index using the search method of the Elasticsearch client. The index name can also be overridden by passing the index parameter to the method. The method returns the search results as a dictionary. this code is trying to create an interface to interact with Elasticsearch for storing and searching chats represented by instances of the Chat_Model class. The ElasticManager class allows for easy integration with Elasticsearch, abstracting away some of the complexities of the Elasticsearch API and making it easier to work with.  </p> <ul> <li>Now its time for root files</li> <li>main.py This script is a Python code that uses OpenAI's GPT-3.5 to generate a response for a given prompt. The conversation history of each user is stored in an Elasticsearch instance using the ElasticManager class from the Models.elastic_crud module.  </li> </ul> <p>The script first loads the API key for OpenAI from an environment variable and sets it as the default API key for the openai package. It also initializes the conversation_history dictionary.  </p> <p>The generate_response() function takes a prompt, user_id, and other optional parameters as input. It then searches for any previous messages by calling the get_user_all_questions() function, retrieves the user's conversation history and appends the new prompt to the context. A request is then sent to OpenAI to generate a response using the context and returns the generated text.  </p> <p>The get_user_all_questions() function retrieves all previous questions asked by a user from Elasticsearch and stores them in a list. The list is then returned to the calling function after updating the global conversation_history dictionary.  </p> <p>Finally, the add_question_to_user_history() function appends the new prompt to the user's conversation history in Elasticsearch along with the current timestamp. The updated conversation_history dictionary is then returned to the calling function.  </p> <p>Overall, this code provides the functionality to generate responses from OpenAI's GPT-3.5 model while keeping track of a user's conversation history using Elasticsearch. server.py* This code provides a simple FastAPI server that exposes an endpoint at /ask-gpt. When this endpoint is called with a valid JSON payload containing a user_id and a question, it generates a response to the question using OpenAI's GPT-3.5 model by calling the generate_response() function from the main module.  </p> <p>The health_check() function provides a simple GET endpoint at / for checking if the service is running. This function returns a dictionary with a \"message\" key indicating that the logging service is running.  </p> <p>The ask_gpt() function listens for POST requests at /ask-gpt. It takes in a Request object containing a JSON payload via the info parameter. The JSON payload should contain a user_id and a question. If these parameters are present, the function retrieves them and passes them as arguments to the generate_response() function. A prompt is constructed from the user's question, and OpenAI's API is called to generate a response.  </p> <p>If the response is successfully generated, it is returned as a JSON object containing a \"response\" key. If there is an error generating the response, a dictionary is returned with a \"message\" key containing the error message.  </p> <p>Overall, this code provides a simple way to integrate OpenAI's GPT-3.5 model into a FastAPI application for generating responses to user queries.  </p>"},{"location":"Chatbot/#general-api-reference","title":"General API Reference","text":"<p>Last Update: 5/21/2023 Health Check: [get] <code>/</code> Ask Question from GPT:  [POST] <code>/ask-gpt</code></p>"},{"location":"Developers/MrTalebElm/","title":"Mr. TalebElm Task list","text":""},{"location":"Developers/MrTalebElm/#acca","title":"ACCA","text":"Task <p>Complete ACCA tutorila.</p> Estimate Start cost ? point 1401/00/00 ? point"},{"location":"Developers/MrTalebElm/#test-cases","title":"test cases:","text":"<ul> <li> Familiar with Cass and Iaas.</li> <li> Setup Dockerized django project on Caas.</li> <li> Setup django project from git.</li> </ul>"},{"location":"Developers/MrTalebElm/#dockerize-gitlab","title":"Dockerize gitlab","text":"Task <p>Dockerize gitlab and setup on arvan cloud. </p> Estimate Start cost ? point 1401/00/00 ? point"},{"location":"Developers/MrTalebElm/#test-cases_1","title":"test cases:","text":"<ul> <li> Setup gitlab on arvan cloud.</li> </ul>"},{"location":"Developers/MrTalebElm/#dockerize-django","title":"Dockerize Django","text":"Task <p>Write Dockerfile for simple django project. You can cooperate with Ms. Salehi in this task.</p> Estimate Start cost 3 Day 1401/00/00 ? point"},{"location":"Developers/MrTalebElm/#test-cases_2","title":"test cases:","text":"<ul> <li> Run django app in docker desktop.</li> </ul>"},{"location":"Developers/MrTalebElm/#rabbitmq-and-docker-compose","title":"RabbitMQ and docker compose","text":"Task <p>Review RabbitMQ documents and implement two small apps for communicating via rabbitMQ. use docker-compose for setup apps and rabbitMQ.</p> Estimate Start cost 2 Day 1401/00/00 ? point"},{"location":"Developers/MrTalebElm/#test-cases_3","title":"test cases:","text":"<ul> <li> Dockerize RabbitMQ and setup pannel.</li> <li> Implement two python apps send/recieve data via rabbitMQ.</li> </ul>"},{"location":"Developers/MrYaghini/","title":"Mr. Yaghini Task list","text":""},{"location":"Developers/MrYaghini/#dockerize-react","title":"Dockerize React","text":"Task <p>Read Docker and Docker-compose document.</p> Estimate Start cost 0 1401/00/00 0"},{"location":"Developers/MrYaghini/#test-cases","title":"test cases:","text":"<ul> <li> Setup docker desktop.</li> <li> Setup simple popular docker-compose project.</li> </ul>"},{"location":"Developers/MrYaghini/#project-documentation","title":"Project documentation","text":"Task <p>Document 'Drone' project.</p> Estimate Start cost 1401/09/30 1401/09/24 1h"},{"location":"Developers/MrYaghini/#test-cases_1","title":"test cases:","text":"<ul> <li> project description.</li> <li> project tree diagram.</li> <li> project feature list.</li> </ul>"},{"location":"Developers/MrYaghini/#landing-page","title":"Landing Page","text":"Task <p>Document 'Drone' project.</p> Estimate Start cost 1401/10/15 1401/09/30 ?h"},{"location":"Developers/MrYaghini/#test-cases_2","title":"test cases:","text":"<ul> <li> Dockerize</li> </ul>"},{"location":"Developers/MrYaghini/#restful-api","title":"Restful API","text":"Task <p>Document 'Drone' project.</p> Estimate Start cost 1401/10/08 1401/09/30 3h"},{"location":"Developers/MrYaghini/#test-cases_3","title":"test cases:","text":"<ul> <li> Starting</li> </ul>"},{"location":"Developers/MrZarei/","title":"Mr. Zarei Task list","text":""},{"location":"Developers/MrZarei/#dockerize-react","title":"Dockerize React","text":"Task <p>Write Dockerfile for simple react project.</p> Estimate Start cost 4h 1401/09/29"},{"location":"Developers/MrZarei/#test-cases","title":"test cases:","text":"<ul> <li> Run react app in docker desktop.</li> </ul> <p>Error</p> <p>Docker desktop not installed correctly yet.</p>"},{"location":"Developers/MrZarei/#docker-compose-for-react-and-nginx","title":"Docker-compose for React and NGINX","text":"Task <p>Write Dockerfile for react project and NGINX, then use docker-compose for setup both of them.</p> Estimate Start cost 4h 1401/09/29"},{"location":"Developers/MrZarei/#test-cases_1","title":"test cases:","text":"<ul> <li> Run react app and NGINX in docker-compose.</li> </ul> <p>Error</p> <p>Docker desktop not installed correctly yet.</p>"},{"location":"Developers/MrZarei/#project-documentation","title":"Project documentation","text":"Task <p>Document \"Satellite communicator and Data collector\" project.</p> Estimate Start cost 8h 1401/09/24 ? point"},{"location":"Developers/MrZarei/#test-cases_2","title":"test cases:","text":"<ul> <li> project description.</li> <li> project tree diagram.</li> <li> project feature list.</li> </ul>"},{"location":"Developers/MrZarei/#project-diagram","title":"Project Diagram","text":"Task <p>Document \"Satellite communicator and Data collector\" project.</p> Estimate Start cost 2h 1401/09/06 ? point"},{"location":"Developers/MrZarei/#test-cases_3","title":"test cases:","text":"<ul> <li> more details for diagram.</li> </ul>"},{"location":"Developers/MrZarei/#project-security","title":"Project Security","text":"Task <p>Document \"Satellite communicator and Data collector\" project.</p> Estimate Start cost ?h 1401/09/08 ? point"},{"location":"Developers/MrZarei/#test-cases_4","title":"test cases:","text":"<ul> <li> research about security.</li> </ul>"},{"location":"Developers/MrZarei/#documents","title":"Documents","text":"Task <p>Documantation for Dr Shahrabi.</p> Estimate Start cost 8h 1401/09/06 ? point"},{"location":"Developers/MsSabahi/","title":"Ms. Sabahi Task list","text":""},{"location":"Developers/MsSabahi/#reading-elasticsearch-and-kibana-documentation","title":"Reading Elasticsearch and kibana documentation","text":"Task <p>Read Elasticsearch and kibana document.</p> Estimate Start cost 8h 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases","title":"test cases:","text":"<ul> <li> Understand index and query in ELK.</li> <li> Get elasticsearch info in Kibana Dev envirment.</li> </ul>"},{"location":"Developers/MsSabahi/#crud-operation-on-elk","title":"CRUD Operation on ELK","text":"Task <p>Create Index, implement CRUD operation and query on ELK.</p> Estimate Start cost 2h 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases_1","title":"test cases:","text":"<ul> <li> Create simple index.</li> <li> Implement CRUD.</li> <li> Implement query.</li> </ul>"},{"location":"Developers/MsSabahi/#dockerize-django","title":"Dockerize Django","text":"Task <p>Write Dockerfile for simple django project.</p> Estimate Start cost 1h 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases_2","title":"test cases:","text":"<ul> <li> Run django app in docker desktop.</li> </ul>"},{"location":"Developers/MsSabahi/#dockerize-django-and-elasticsearch","title":"Dockerize Django and elasticsearch","text":"Task <p>Write Dockerfile for django project and ELK, then use docker-compose for setup both of them.</p> Estimate Start cost 1h 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases_3","title":"test cases:","text":"<ul> <li> Run django app and ELK in docker-compose.</li> <li> CRUD operation on elasticsearch via django app.</li> </ul>"},{"location":"Developers/MsSabahi/#swagger-and-redoc","title":"Swagger and Redoc","text":"Task <p>Setup swagger and redoc for django apps.</p> Estimate Start cost 1h 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases_4","title":"test cases:","text":"<ul> <li> show swagger pannel.</li> <li> show redoc pannel.</li> </ul>"},{"location":"Developers/MsSabahi/#microservices","title":"Microservices","text":"Task <p>Create map and tile manager microservices.</p> Estimate Start cost 1w 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases_5","title":"test cases:","text":"<ul> <li> map service.</li> <li> stile manager service.</li> </ul>"},{"location":"Developers/MsSabahi/#handler","title":"Handler","text":"Task <p>Create handler for gee service.</p> Estimate Start cost 1w 1401/00/00"},{"location":"Developers/MsSabahi/#test-cases_6","title":"test cases:","text":"<ul> <li> checking the connection between services.</li> </ul>"},{"location":"DotNet%20Project%20Structure/Description/","title":"Description","text":"<p>Certainly! Here's an example of how to create a documentation website using MkDocs to describe the .NET 7 project structure using Clean Architecture.</p>"},{"location":"DotNet%20Project%20Structure/Description/#introduction","title":"Introduction","text":"<p>In this document, we'll explore the structure of a .NET 7 project following the Clean Architecture pattern. Clean Architecture is a software design philosophy that emphasizes separation of concerns and decoupling dependencies between different layers of an application. This helps to make code more modular, testable, and maintainable over time.</p>"},{"location":"DotNet%20Project%20Structure/Description/#project-structure","title":"Project Structure","text":"<p>The project structure for a .NET 7 application following Clean Architecture consists of four main layers:</p> <ol> <li>Presentation Layer</li> <li>Application Layer</li> <li>Domain Layer</li> <li>Infrastructure Layer</li> </ol> <p>Each layer has its own responsibilities and dependencies, and they are arranged in a way that allows each layer to interact only with the layer directly below it.</p>"},{"location":"DotNet%20Project%20Structure/Description/#presentation-layer","title":"Presentation Layer","text":"<p>The Presentation Layer is responsible for handling user input and output. It consists of user interface components such as controllers, views, and razor pages. These components should be thin and delegate most of their work to the Application Layer. In our structure, the Presentation Layer is at the top, closest to the user.</p>"},{"location":"DotNet%20Project%20Structure/Description/#application-layer","title":"Application Layer","text":"<p>The Application Layer contains the business logic of the application. It coordinates interactions between the Presentation Layer and the Domain Layer, and it is where you would implement use cases or services. The Application Layer should not rely on any lower-level implementation details, such as databases or external APIs. Instead, it depends on abstractions defined in the Domain Layer.</p>"},{"location":"DotNet%20Project%20Structure/Description/#domain-layer","title":"Domain Layer","text":"<p>The Domain Layer represents the core business logic of the application. It contains entities, value objects, and business rules that define the behavior of the system. The Domain Layer should not depend on any infrastructure or application-specific details. Instead, it should define interfaces that the Application Layer can use to interact with it.</p>"},{"location":"DotNet%20Project%20Structure/Description/#infrastructure-layer","title":"Infrastructure Layer","text":"<p>The Infrastructure Layer provides implementations for the interfaces defined in the Domain Layer. It is where you would put code to interact with databases, external APIs, or other infrastructure components. The Infrastructure Layer depends on the Domain Layer but not on any higher-level layers such as the Application Layer or Presentation Layer.</p>"},{"location":"DotNet%20Project%20Structure/Description/#unit-tests","title":"Unit Tests","text":"<p>Unit tests are automated tests that test individual units of code in isolation. In a Clean Architecture project, unit tests should be written for each component in the Presentation, Application, and Domain Layers. These tests should not depend on any external resources such as databases or APIs, and they should run quickly and reliably.</p>"},{"location":"DotNet%20Project%20Structure/Description/#integration-tests","title":"Integration Tests","text":"<p>Integration tests are automated tests that test the interactions between different components in the system. In a Clean Architecture project, integration tests should be written for the interactions between the Application Layer and the Infrastructure Layer. These tests should ensure that the system as a whole behaves correctly, and they should be run less frequently than unit tests due to their longer execution time.</p>"},{"location":"DotNet%20Project%20Structure/Description/#project-diagram","title":"Project Diagram","text":"<p>Here's a diagram of how the different layers fit together in our Clean Architecture structure:</p> <pre><code>+----------------+\n| Presentation   |\n+----------------+\n|  Application   |\n+----------------+\n|    Domain      |\n+----------------+\n| Infrastructure |\n+----------------+\n|     Tests      |\n+----------------+\n</code></pre> <p>Project Structure</p> <pre><code>flowchart TB\n\nsubgraph Presentation\n    subgraph Controllers\n        Controller1\n        Controller2\n    end\n    subgraph Views\n        View1\n        View2\n    end\n    subgraph RazorPages\n        RazorPage1\n        RazorPage2\n    end\nend\n\nsubgraph Application\n    subgraph UseCases\n        UseCase1\n        UseCase2\n    end\n    subgraph Services\n        Service1\n        Service2\n    end\nend\n\nsubgraph Domain\n    subgraph Entities\n        Entity1\n        Entity2\n    end\n    subgraph ValueObjects\n        ValueObject1\n        ValueObject2\n    end\n    subgraph BusinessRules\n        Rule1\n        Rule2\n    end\nend\n\nsubgraph Infrastructure\n    subgraph Repositories\n        Repository1\n        Repository2\n    end\n    subgraph DataSources\n        DataSource1\n        DataSource2\n    end\nend\n\nsubgraph Tests\n    subgraph UnitTests\n        UnitTest1\n        UnitTest2\n    end\n    subgraph IntegrationTests\n        IntegrationTest1\n        IntegrationTest2\n    end\nend\n\nPresentation --&gt; Application\nApplication --&gt; Domain\nDomain --&gt; Infrastructure\nTests --&gt; Application\nTests --&gt; Domain\nTests --&gt; Infrastructure</code></pre> <p>As you can see, each layer only knows about the layer directly below it and communicates through well-defined interfaces. This makes it easy to maintain and test each layer independently.</p>"},{"location":"DotNet%20Project%20Structure/Description/#conclusion","title":"Conclusion","text":"<p>By following the Clean Architecture pattern, we can create applications that are modular, testable, and maintainable over time. In this document, we explored the four main layers of a .NET 7 project using Clean Architecture and how they interact with each other. We also provided a diagram to help you visualize the structure of your own projects.</p>"},{"location":"Drone/Backlog/","title":"Backlog","text":""},{"location":"Drone/Backlog/#backlog-of-drone-project","title":"Backlog of Drone Project","text":"<p>Django server for REST operation.</p> <p>Design UI/UX for mobile app.</p> <p>Define product name. </p> <p>web-base user panel for monitor farm land state and spraying history. </p>"},{"location":"Drone/Description/","title":"Description","text":""},{"location":"Drone/Description/#description","title":"Description","text":"<p>The drone system is responsible for managing the drones flight, the drones data and spraying teams.</p>"},{"location":"Drone/Description/#diagram","title":"Diagram","text":"<pre><code>flowchart TB\n\n    classDef Elk fill:#d500f933;\n\n    style Gateway fill:#00c85333\n\n    subgraph Internet\n\n    subgraph Mobile\n    Drone\n    end\n\n    end\n\n\n    subgraph Firewall\n    Gateway\n    end\n\n    Internet --Rest--&gt; Gateway\n    Gateway --Rest--&gt; Financial\n    Gateway --Rest--&gt; DroneBackend[Drone Backend]\n</code></pre>"},{"location":"Drone/Description/#technologies","title":"Technologies","text":"<ul> <li> MAUI</li> <li> Direct WiFi</li> <li> .net core</li> </ul>"},{"location":"Drone/Description/#database","title":"Database","text":"<ul> <li> ElasticSearch</li> </ul>"},{"location":"Drone/Description/#sub-project","title":"Sub Project","text":"<ul> <li>Drone (Mobile-Frontend). Implement via <code>MAUI</code></li> <li>Drone server (Backend). Implement via <code>.net core</code></li> </ul>"},{"location":"Drone/Description/#mobile-app","title":"Mobile App","text":"<p>The mobile app is installing on the radio controller and consists of two parts, <code>mission</code> and <code>operation</code></p> <p>In the mission part, define the mission of the drone, including the scope of agricultural land, the scope of the barriers(<code>Add point</code>, <code>Delete Point</code>). And the drone <code>settings</code> include height, spray width, pump efficiency, poison amount, poison flow rate, speed and height of returning home and the necessary explanations for this mission. And by doing the <code>processing</code>, the mission, drone speed and the optimal path of the drone will be determined. After this, if the pilot wants, he can manually change the angle of the drone's movement path. And then the set mission template is <code>saved</code> and send to <code>drone backend</code> for storage.</p> <p>In the operation part, the drone is connecting to the application, and after selecting the saved mission template and <code>sending</code> it to the drone, by sending the <code>start</code> command from the application, the spraying flight of the drone starts. And in real time, the data of the <code>drone status</code> is sent to the application through wifi connection and mavlink protocol and it is shown on the operation page. And by sending the <code>stop</code> command from the application, the drone returns to the home point.</p> <p>On the <code>main page</code>, the saved mission <code>templates</code> can be <code>deleted</code>, viewed and selected for <code>editing</code> on the mission page and <code>open</code> for sending to the drone on the operation page.</p> <p>On the registry page, by sending the mobile number and password to <code>gateway</code>, the token is sent to the user, and the imei code together with token is sent to the <code>Financial</code>. And if the user subscribes to the drone application, the license will be sent to the app, and the user will enter the <code>main page</code> by restarting the application.</p> <p>If the drone exits the auto mode during operation, the rest of the mission is <code>saved</code> and after the drone returns home to solve the problem, including charging the battery and filling the poison tank, by <code>sending the rest</code> of the mission from the application and the command to <code>start</code>, the drone for Carrying out the rest of the mission flies</p>"},{"location":"Drone/Description/#drone-backend","title":"Drone Backend","text":"<p>This microservice includes four methods.</p> <p><code>GetAllTemplates</code>: In this method, all the mission templates can be received based on specifying the page.</p> <p><code>GetTemplates</code>: In this method, you can receive the mission templates of each device based on the imei code in general or for a specific name by specifying the page.</p> <p><code>TemplatesStorage</code>: In this method, the specifications of the mission templates sent by the mobile app are saved for each device.</p> <p><code>TemplatesLogicalDelete</code>: In this method, the mission templates are logically deleted based on the name and imai code, either directly or because a new version of them has come for storage.</p>"},{"location":"Drone/Description/#user-flow","title":"User flow","text":"<pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n  MainPage --&gt; fork_state\n  fork_state --&gt; Mission\n  fork_state --&gt; Operation\n  fork_state --&gt; Templates\n\n  Mission --&gt; Process\n  Mission --&gt; SaveTemplate\n  Mission --&gt; AddPoint\n  Mission --&gt; DeletePoint\n  Mission --&gt; Setting\n  Operation --&gt; Send\n  Operation --&gt; DroneStatus\n  Operation --&gt; Start\n  Operation --&gt; Stop\n  Templates --&gt; Edit\n  Templates --&gt; Open\n  Templates --&gt; Delete</code></pre>"},{"location":"Drone/Description/#team","title":"Team","text":"<ul> <li>Mr Yaghini</li> </ul>"},{"location":"Farming/Backlog/","title":"Backlog","text":""},{"location":"Farming/Backlog/#backlog-of-farming-project","title":"Backlog of Farming Project","text":"<p>User management service.</p> <p>Design UI/UX.</p> <p>Define product name. </p> <p>Map handler service.</p> <p>Google engine feeder service.</p> <p>Sale and licence management service - free user - Firm user</p>"},{"location":"Farming/Description/","title":"Description","text":""},{"location":"Farming/Description/#description","title":"Description","text":"<p>This project is Web application which assist farmer in farming operations.</p>"},{"location":"Farming/Description/#diagram","title":"Diagram","text":"<pre><code>    flowchart TB\n\n    subgraph Handler\n        CachingTiles\n    end\n\n    Map --subscribe/channel--&gt; SocketServer\n    Map --Rest--&gt; Gateway\n    Gateway --Rest--&gt; Handler\n    Handler --Rabbit MQ--&gt; A[GEE Service]\n    Handler --Rabbit MQ--&gt; Publisher\n    Publisher --subscribe--&gt; SocketServer    \n    Publisher --publish--&gt; SocketServer\n    A[GEE Service] --Rabbit MQ--&gt; Handler\n</code></pre>"},{"location":"Farming/Description/#user-flow","title":"User flow","text":"<pre><code>    stateDiagram-v2\n\n    HomePage(Admin) --&gt; Auth,Login\n    Auth,Login --&gt; AdminDashboard\n    AdminDashboard --&gt; UserActivityMonitoring\n\n    HomePage(User) --&gt; Register,Auth,Login\n    Register,Auth,Login --&gt; UserDashboard\n    UserDashboard --&gt; AccessToHistoryOfResults\n    UserDashboard --&gt; DrawPolygon\n\n</code></pre>"},{"location":"Farming/Description/#handler-documentation","title":"Handler documentation","text":"<p>Introduction The handler service is actually a service that receives a request based on satellite images and then, according to the engines it has, processes the request and provides the result to the requester. (The client handler can be a user or another service. If the client is a normal user, he receives the response to his request on the front side. And if it is another service, he can receive the response to his request from the brokers)</p>"},{"location":"Farming/Description/#sub-project","title":"Sub Project","text":"<ul> <li>Map (Frontend). Implement via <code>react js</code></li> <li>Farming (Backend). Implement via <code>django</code></li> <li>Handler (Backend). Implement via <code>django</code></li> <li>GEE (Backend). Implement via <code>python</code></li> </ul>"},{"location":"Farming/Description/#workflow","title":"workflow","text":"<p>1- <code>Agricultural service</code></p> <p>A: When a farmer or a farmer registers a land on the platform, he sends his request in the message structure. which first asks for a date range to see on which days there is an image for its field. The handler, for example, queries gee and creates an index for each date for the next processing request only in an empty form. On the front side, it is possible to receive the query of those dates according to the ID of the land and show them on the timeline.</p> <p>B: At this time, a request from the agricultural service is sent to the handler to receive the desired index image. The handler also sends the request to one of its engines such as gee for processing. After receiving the result from gee, it stores and sends the result for the sent request. (In order to display the result instantly in the user's browser, the result is sent through the socket)</p> <p>2- <code>image management service</code></p>"},{"location":"Farming/Description/#models","title":"models","text":"<p>Available in the <code>models.py</code> module</p>"},{"location":"Farming/Description/#geemodel","title":"GeeModel","text":"<p>This model is for when we intend to send a request to receive the ndvi index image or other indices from the handler. For this purpose, we send our request in a specific message structure. And the result is stored in the model. Of course, this model focuses on receiving the result (image) from Google Earth Engine.</p> Key value required Description <code>svc_type</code> NDVI To distinguish and separate the results by the handler <code>indicator</code> Ndvi Quality index <code>filename</code> filename The name of the tile in Arvan cloud bucket to access and etc. <code>region</code> polygon Result area to use elastic query feature <code>st_date</code> 2000-07-01 start date <code>end_date</code> 2000-08-01 end date <code>resources</code> List(polygon) sources and areas used for image mosaic <code>status</code> status_string status of process"},{"location":"Farming/Description/#imageprocess","title":"ImageProcess","text":"<p>This model is actually a model that creates an instance for each image request to the handler. And finally, when the handler was able to determine the response and values of this request, it returns the response with its specified identifier.</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 value required Description <code>image_id</code> uuid Request ID <code>indicator</code> Ndvi Quality index <code>image_region</code> polygon Request area <code>st_date</code> 2000-07-01 start date <code>end_date</code> 2000-08-01 end date <code>image_base64</code> Base64_string Base64 image <code>image_values</code> List[] Dataset value of pixel points <code>mean_value</code> 2.3 Average values <code>resources</code> List(polygon) sources and areas used for image mosaic <code>status</code> status_string status of process"},{"location":"Farming/Description/#farmmodel","title":"FarmModel","text":"<p>This model is actually for the time when a farmer or industrialist plans to register a land with his desired name.</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 value required Description <code>farm_name</code> Phone+uuid Farm name <code>farm_region</code> polygon Farm region <code>centroid</code> (Lat,long) central point"},{"location":"Farming/Description/#farmresultmodel","title":"FarmResultModel","text":"<p>These documents are created by the handler when the dates are received from gee. Any agricultural user in his timeline can request any of these documents whose status is not completed so that the results are processed and their information is available with active status.</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 value required Description <code>farm_id</code> Phone+uuid Farm id <code>indicator</code> Ndvi Quality index <code>farm_date</code> 2000-06-18 date <code>farm_image</code> Base64_string Base64 image <code>farm_values</code> list() Dataset value of pixel points <code>min_value</code> 2.7 Average values <code>status</code> status_string status of process"},{"location":"Farming/Description/#farmdatesmodel","title":"FarmDatesModel","text":"<p>When the farmer registers his land, a request is sent to the handler, and the handler inquires about the date of the available images of that land from gee or etc.</p> <p>This model is temporarily used by the handler and etc.</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 value required Description <code>farm_id</code> Phone+uuid Farm id <code>svc_type</code> type The type of service that must be specified for the handler <code>dates</code> list(date,..) all dates available image"},{"location":"Farming/Description/#sample-requests-message-structure","title":"Sample requests (message structure)","text":""},{"location":"Farming/Description/#request-types","title":"Request types","text":"<p>This value can be accessed and selected from the <code>HANDLER_REQ</code> class of enumeration data type. which is available in the <code>utils</code> module. Currently, it includes the following value:</p> <p><code>RASTER_DATA</code> = 1</p> <p><code>DATES</code> = 2</p>"},{"location":"Farming/Description/#indicators","title":"Indicators","text":"<p>This value can be accessed and selected from the <code>HANDLER_INDICATOR</code> class of enumeration data type. which is available in the <code>utils</code> module. Currently, it includes the following value:</p> <p><code>NDVI</code> = 1</p>"},{"location":"Farming/Description/#search-mechanisms","title":"Search mechanisms","text":"<p>The types of search engines are as follows:</p> <ul> <li> <p>When the handler receives a new request, does it check whether it has already received a part of the requested area or the whole of it? If the entire area already has a request, it will process the request immediately and send the result to the user. Otherwise, if the area is not available, it puts the request in the processing queue to be processed with other requests.</p> </li> <li> <p>When the handler, for example, receives a response from gee in response to its processing request, it first searches and filters the commonality of that response with the requests being processed by the handler. It then searches each of those requests again with all available processing results and responses to see if it can complete and satisfy the requested area. If it succeeds, it will calculate the result and after merge and clip etc., it will send that result to the user. (Note that only those results that have a successful status are searched. Also, the results are filtered according to the required date)</p> </li> <li> <p>When the handler receives a result from gee, the actual result of the processing may not be complete. (due to the mosaic of current images). For this purpose, he should make a query so that the required results are requested from gee again.</p> </li> </ul>"},{"location":"Farming/Description/#checking-the-images-and-ready-results-is-done-only-in-2-times","title":"Checking the images and ready results is done only in 2 times:","text":"<ul> <li> <p>When a new request is received by the handler: the handler searches whether it can answer this request or not. If it has a cache, it returns the request and returns its response.</p> </li> <li> <p>When the handler receives a response from gee or another engine, it searches among the requests being processed and checks which of the requested areas has something in common with the received response. Then, for each subquery, it searches through its own results to see if it can answer the entire current request area. If it can answer the request area, it will store and send the answer to the user's request at the same stage. Otherwise, the user's request remains in processing. (This expectation is reasonable only when it is ensured that the requested non-existent regions are being processed)</p> </li> </ul>"},{"location":"Farming/Description/#getting-to-know-the-rasterlib-module","title":"Getting to know the <code>rasterlib</code> module","text":"<p>This module is used to merge the image tiles which are usually in tiff format, then cut and clip the specific requested area and finally receive the image output in png format. It includes different sections:</p> <p><code>merge_tiles</code>: In the first argument, this function receives a list of image tile sources in tiff format, then stores the merged result in the path of the second received argument.</p> <p><code>merge</code>: <code>merge_tiles</code> function uses this function to merge its images first.</p> <p><code>extract_values</code>: This function stores raster values for geographic location and similar values, also calculates the mean of values such as ndvi.</p> <p><code>export_ndvi</code>: This function reads the ndvi results according to the received dataset (tiff file) and then assigns them a color palette in the range of 0 to 1. And finally, it stores the png file in the received destination address.</p> <p><code>generate_tile</code>: This function generally simultaneously <code>merge_tiles</code>, then cuts and extracts the requested area on the merged tile. Finally, using the <code>export_ndvi</code> function, the result of the png image is stored in ndvi. Finally, it can convert the resulting image to <code>base_encode64</code> using the <code>base64_image</code> function and use it.</p>"},{"location":"Farming/Description/#getting-to-know-the-receiver-module","title":"Getting to know the <code>receiver</code> module","text":"<p>This is the same gee service.</p>"},{"location":"Farming/Description/#setting-up","title":"Setting up :","text":"<p><code>At first, this service creates a process using the licenses it has obtained from gee. So that each license is related to one process. When it receives a new request from its connection queue, it divides the new requests among the processes in order so that it can perform several processes at the same time and the process does not stop.</code></p> <p>Procedures for obtaining a new license from Google Earth Engine</p>"},{"location":"Farming/Description/#tasks","title":"Tasks :","text":"<ul> <li>gee must try a certain number of times for each request, for example 4 times, to receive the result and send it to the handler. If it still fails to process after these attempts, it should still report the failure result. (The handler takes the appropriate decision after receiving the processing status.)</li> <li>gee must be able to remain stable and store its logs in case of errors and emergency situations. (be ready for all restrictions)</li> <li>It must have access to several licenses and be able to behave in such a way that it is not recognized by gee as an abuser, and on the other hand, it must be able to use all its processing power and at a reasonable speed.</li> </ul>"},{"location":"Farming/Description/#getting-to-know-the-processing-module","title":"Getting to know the <code>processing</code> module","text":"<p>This module interacts with Google Earth through REST.</p> <p>It includes various <code>processing</code> functions:</p> <ul> <li><code>get_ndvi</code>: the gee service calculates the ndvi index of the requested image (operations such as cloud mask on the image with clouds, image mosaic, etc.) and sends the result to the handler in the form of a tiff file. The handler also caches it, and responds to common area requests if possible (in tiff file format).</li> <li><code>get_date_list</code>: In this function, the collection of sentinel2 images are filtered based on the received area and received date range. And then the date of the available images are returned as a list. The rest of the functions are more helpful to the mentioned functions. For example, the functions used for the cloud mask and...</li> </ul>"},{"location":"Farming/Description/#getting-to-know-the-bucket-module","title":"Getting to know the <code>bucket</code> module","text":"<p>This module contains various parts for using object storage. At first, in the constructor function, according to the values in the <code>setting</code> module, it creates a connection with the bucket or object storage.</p> <p><code>DownUploadFile</code>: receives a source file address and destination file name as input. It receives the file from the sending source and stores it in the bucket with the output name.</p> <p><code>GetDownloadLink</code>: By receiving the file name and an expiration time, it creates a temporary address to access the desired private file.</p>"},{"location":"Farming/Description/#getting-to-know-the-elastic-module","title":"Getting to know the <code>Elastic</code> module","text":"<p>This module contains different parts for using elastic. Contains the ElasticManager class. When using this class, it automatically reads the elastic connection address from the settings module and creates a connection through it with elastic. It includes the following functions:</p> <p><code>insert_to</code>: This function receives parameters such as uuid, document and index, and then storage is done based on the received parameters.</p> <p><code>Insert</code>: This function only receives the document and index from the input and saves it. (for times when the ID is not important to us or we intend to use a suitable unique ID)</p> <p><code>Get</code>: This function receives the uuid and index from the input, then returns the result in the output.</p> <p><code>Search</code>: this function, query as a dictionary; It also receives the index from the input, then returns the result in the output.</p> <p><code>create_index</code>: This function creates the desired index in Elastic according to the name of the index and the custom mapping it receives.</p>"},{"location":"Farming/Description/#getting-to-know-the-gee_custom_query-module","title":"Getting to know the <code>gee_custom_query</code> module","text":"<p>This module contains the set of custom queries needed and used for gee: It has a class named <code>GeeCustomQueries</code>, which when created is an object of the <code>GeeModel</code> model, based on which the desired queries can be made.</p> <p>It includes the following queries:</p> <p><code>search_by_uuid</code>: performs the query based on the document ID in the gee index. <code>polygon_within</code> : Used for area query. It receives the coordinates of the area in the form of a polygon, date and index as an input for querying and can be used for combined search.</p>"},{"location":"Farming/Description/#introduction-to-base64_encode-module","title":"Introduction to <code>base64_encode</code> module","text":"<p>This module has a class called <code>ImageManager</code>, which can be obtained using the <code>get_base64_png</code> function and calling it with the input value of the path of the png image file, that image file can be received as a base64 string.</p> <p>Getting to know the <code>settings</code> module This module has the required values for authentication in the bucket service, elastic search, etc.</p>"},{"location":"Farming/Description/#technologies","title":"Technologies","text":"<ul> <li> Django</li> <li> React</li> <li> <p> Redis :</p> <p>In order for the gateway to be able to allow each user at any time, only one request being processed, it needs to consider a variable in the Redis cache for the ID of that user and the value of the processing status or etc. the handler also has access to this value, and if in its review, it finds that the processing time of this user has expired, it updates the result and deletes it from the cache. The gateway also accepts the new request from the user and sends it to the handler if it sees that the user is not processing the request. </p> </li> <li> <p> RabbitMQ : </p> <ul> <li> <p>When the handler intends to send a request to its engines for processing, it adds it to their processing queue as a task.</p> </li> <li> <p>When the engines want to inform the handler of the processing request status, they add a new item to the handler's processing result queue. By ensuring the successful status of the received result, the handler can respond to the shared requests it is processing.</p> </li> <li> <p>When the handler wants to send a result to the users through the socket, it sends the new message to the publisher's rabbit queue along with the process id that the user listens to.</p> </li> </ul> </li> <li> <p> Elastic Search :</p> <p>All the models related to the handler service are stored in Elastic Search in order to use the possibility of suitable queries that it provides us. </p> </li> <li> <p> Celery : </p> <p>We use this possibility to avoid blocking and stop processing for each processing request, as well as proper management of threads and processes. Our tasks are also specified in the tasks module. and are accessible. </p> </li> </ul>"},{"location":"Farming/Description/#how-to-communicate","title":"How to communicate","text":"<ul> <li>Storage and cache: bucket, elastic</li> <li>Search: elastic search</li> <li>Response: RabbitMQ and socket cluster</li> <li>Storage of events: log and etc</li> </ul>"},{"location":"Farming/Description/#team","title":"Team","text":"<ul> <li>Ms. Moradi</li> <li>Mr. TalebElm</li> </ul>"},{"location":"Financial%20Dashboard/Baclog/","title":"Baclog","text":""},{"location":"Financial%20Dashboard/Baclog/#backlog-of-financial-dashboard","title":"Backlog of Financial Dashboard","text":""},{"location":"Financial%20Dashboard/Description/","title":"Description","text":""},{"location":"Financial%20Dashboard/Description/#description","title":"Description","text":"<p>This project is Web application for financal managment in spaceomid.</p>"},{"location":"Financial%20Dashboard/Description/#technologies","title":"Technologies","text":"<ul> <li>Javascript, Typescript</li> <li>React, Nextjs</li> <li>Tailwind css</li> <li>Mongodb</li> <li>sms panel</li> <li>PWA</li> </ul>"},{"location":"Financial%20Dashboard/Description/#diagram","title":"Diagram","text":""},{"location":"Financial%20Dashboard/Description/#feature-list","title":"Feature List","text":"<ol> <li>Authentication<ul> <li>Login, Register, ... using jwt tokens</li> </ul> </li> <li>SMS Panel<ul> <li>Simple sms alarms and notifications for admins, users and creator</li> </ul> </li> <li>User, Group, Roles, Permissions<ul> <li>Simple Groups and Group managment for advisors(Admins) and creator</li> </ul> </li> <li>MongoDb Atlas<ul> <li>MongoDb atlas for storing data</li> </ul> </li> <li>...</li> </ol>"},{"location":"Financial%20Dashboard/Description/#team","title":"Team","text":"<ul> <li>Mr. Zarei</li> </ul>"},{"location":"Image%20Processing%20Platform/Baclog/","title":"Baclog","text":""},{"location":"Image%20Processing%20Platform/Baclog/#backlog-of-image-processing-platform-project","title":"Backlog of Image Processing Platform Project","text":"<p>Map management service</p> <p>Design UI/UX.</p> <p>Define product name. </p> <p>Drawing operation service.</p> <p>3party tile adapter service.</p>"},{"location":"Image%20Processing%20Platform/Description/","title":"Description","text":""},{"location":"Image%20Processing%20Platform/Description/#description","title":"Description","text":"<p>This project is Web application which manage map tile and drawing operations for farming purpose.</p>"},{"location":"Image%20Processing%20Platform/Description/#diagram","title":"Diagram","text":"<pre><code>flowchart TB\n\n\n\n    subgraph Handler\n        CachingTiles\n    end\n\n    Map --subscribe/channel--&gt; SocketServer\n    Map --Rest--&gt; Gateway\n    Gateway --Rest--&gt; Handler\n    Handler --Rabbit MQ--&gt; A[SOE Service]\n\n    Handler --Rabbit MQ--&gt; Publisher\n    Publisher --subscribe--&gt; SocketServer    \n    Publisher --publish--&gt; SocketServer\n    A[SOE Service] --Rabbit MQ--&gt; Handler\n</code></pre>"},{"location":"Image%20Processing%20Platform/Description/#user-flow","title":"User flow","text":"<pre><code>    flowchart TB\n\n    E[HomePage-Admin] --&gt; Auth,Login\n    Auth,Login --&gt; AdminDashboard\n    AdminDashboard --&gt; H[Users Search History]\n    AdminDashboard --&gt; ImageManagement\n\n    F[HomePage-User] --&gt; Register,Auth,Login\n    Register,Auth,Login --&gt; UserDashboard\n    UserDashboard --&gt; G[Own User Search History]\n    UserDashboard --&gt; I[Draw Polygon]\n    I --&gt; D[Receive Services and Related Images]\n</code></pre>"},{"location":"Image%20Processing%20Platform/Description/#sub-project","title":"Sub Project","text":"<ul> <li>Map (Frontend). Implement via <code>react js</code></li> <li>SOE (Backend). Implement via <code>fastapi</code></li> </ul>"},{"location":"Image%20Processing%20Platform/Description/#image-collection","title":"Image Collection","text":"<p>Elastic image index for storing images</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 type required Description <code>image_id</code> text image id in its metadata <code>acquisition-time</code> date date of image acquisition <code>image-corners</code> geo_shape image corners <code>owner</code> text owner of the image <code>platform-type</code> text platform type of image acquisition (it can be satellite, drone or airplane) <code>platform-name</code> text platform name of image acquisition <code>sensor-type</code> text sensor type of image acquisition (it can be RGB, PAN, ...) <code>filename</code> text filename of the image <code>resolution</code> text resolution of image"},{"location":"Image%20Processing%20Platform/Description/#image-sources","title":"Image Sources","text":"<p>Elastic index for storing image sources to search the image sources faster</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 type required Description <code>owner</code> text owner of the image <code>platform-type</code> text platform type of image acquisition (it can be satellite, drone or airplane) <code>platform-name</code> text platform name of image acquisition <code>cumulative-polygon</code> geo_shape The area where we have the image"},{"location":"Image%20Processing%20Platform/Description/#search-collection","title":"Search Collection","text":"<p>Elastic index for storing users searches</p> \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Key\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 type required Description <code>user_id</code> text user id <code>timestamp</code> date <code>polygon</code> text The area where the user searched"},{"location":"Image%20Processing%20Platform/Description/#soe-api","title":"SOE API","text":"<p>It has three main routes</p> <ul> <li>/explore-image : get a polygon from the user and returns the images that intersects with the input polygon.</li> <li>/searches-history : return 10 latest searches</li> <li>/images-source-categories : returns image sources</li> </ul>"},{"location":"Image%20Processing%20Platform/Description/#team","title":"Team","text":"<ul> <li>Ms. Sabahi</li> </ul>"},{"location":"Load%20Test/Load-Test/","title":"Load Test Documentation","text":"<p>This documentation provides information about how to run load tests and save them database and also see the results  </p>"},{"location":"Load%20Test/Load-Test/#technologies-used-in-project","title":"Technologies Used in Project","text":"<ul> <li>K6.io</li> <li>Grafana</li> <li>InfluxDb</li> <li>Docker</li> </ul>"},{"location":"Load%20Test/Load-Test/#getting-started","title":"Getting Started","text":"<p>In order to see the test results in dashboard you need to run InfluxDb and Grafana(they are dockerized and ready to use, just need to build and run them) beforehand, However, for running the tests they are not necessary and you can check the results in terminal that you run the the tests(actually the terminal result is more detailed). Tests are written in scenario based structure and in order to findout how they work and modifing them check the official document here</p>"},{"location":"Load%20Test/Load-Test/#general-workflow-of-the-project","title":"General WorkFLow of the Project","text":"<p>After running inial commands in terminal(described in detail later in this this page), you device will increase the load on the target service and at the end of test you can see the result in the terminal and in Grafana dashboard(IF YOU ENABLED IT!)  </p>"},{"location":"Load%20Test/Load-Test/#command-reference","title":"Command Reference","text":"<p>Last Update: 4/24/2023 JUST MAKE SURE YOU ARE IN THE SAME DIRECTORY AS THE LOAD TEST FILE IS! To run the test locally(Not sending results to database): <code>k6 run Load-Test.js</code> (Change the Load-Test.js to name of the loadtest file you want!) To the test and send the result to database for dashboard <code>k6 run --out influxdb=Grafana-server-address Load-Test.js</code>(Change the Load-Test.js to name of the loadtest file you want!)  </p>"},{"location":"Load%20Test/Load-Test/#running-influxdb-and-grafana-dashboar-services","title":"Running InfluxDb and Grafana dashboar services","text":"<p>For running InfluxDb and Grafana dashboard IF THE DASHBOARD IS RUNNING JUST NAVIGATE TO YOUR GRAFANA HOME PAGE AND GO TO THE DASHBOARD SECTION! <code>SERVER-ADDRESS:3000/</code> IF YOU WANT TO SETUP THE DASHBOARD FOLLOW THE INSTRUCTION. You can access the latest configs from <code>git clone https://github.com/grafana/k6 &amp;&amp; cd k6</code>. It Contains all the files and examples, However the file you need is the docker compose that is described Here:  </p> <p><pre><code>version: '3.4'\n\nnetworks:\nk6:\ngrafana:\n\nservices:\ninfluxdb:\nimage: influxdb:1.8\nnetworks:\n- k6\n- grafana\nports:\n- \"8086:8086\"\nenvironment:\n- INFLUXDB_DB=k6\n\ngrafana:\nimage: grafana/grafana:latest\nnetworks:\n- grafana\nports:\n- \"3000:3000\"\nenvironment:\n- GF_AUTH_ANONYMOUS_ORG_ROLE=Admin\n- GF_AUTH_ANONYMOUS_ENABLED=true\n- GF_AUTH_BASIC_ENABLED=false\nvolumes:\n- ./grafana:/etc/grafana/provisioning/\n</code></pre> Now, we will use the above docker-compose.yml to set up influxdb and Grafana in our instance using docker-compose, as seen in the YAML file we are using influxdb version 1.8 and have mapped container port 8086 with the host port for influxdb and our database name is k6. Similarly, for Grafana we will be running on port 3000. Run the below command which will pull in all the applicable docker images and set up our containers using docker-compose. <code>docker-compose up -d influxdb grafana</code>(-d is for detach mode, to see the output without -d!)  </p> <p>Access the Grafana dashboard from the browser Now its time to connect to the server that is runnig Grafana service from browser(Find the IP Address): <code>SERVER-ADDRESS:3000/login</code> </p> Default-user-and-pass <p>Username: admin Password: admin</p> <p>Navigate to the URL: <code>SERVER-ADDRESS:3000/datasources</code> When you open the data source you can view the details, here You can verify the URL and database name which was configured in the YAML file. Post running this k6 run command, You set of results will be pushed to the influxdb database called k6, now in order to visualize Your run results we can configure a Grafana dashboard using the below steps: 1. Navigate to your Grafana home page and go to the Dashboard section 2. Under New, select the import option 3. In the Import page, we will use ID: 2587 which is a pre-configured dashboard available for k6 load tests in Grafana. For more information, you can refer to this Link 4. In next page, we can add 2587 in the textbox and click Load button. 5. Finally, select the source as \u201cmyinfluxdb (Default)\u201d option and click on the Import button which will load up our dashboard.  </p> <p>Results </p> 5-1-2023 <p>GateWay:   Signup:     390 Concurrent User   SignIn(In 90 Seconds Duration):     100   Resources:     PostgreSQL:       CPU: 1Core       RAM: 2GB     GateWay:       CPU: 1Core       RAM: 1GB  </p> <p>Drone: 80 is OK Resources:   Financial:     CPU: 1Core     RAM: 1GB  </p> <p>WebSocket:   Both socket server and Socket publisher had 1GB of Ram and 1Core CPU   Because of async nature of node.js and FastAPI didn\u2019t break even at 1 million requests!   Publish rate (with API call and not rabbit) was between 100-150.   Publish rate With RabbitMQ More than 2000.</p>"},{"location":"Satellite%20Communicator/Backlog/","title":"Backlog","text":""},{"location":"Satellite%20Communicator/Backlog/#backlog-of-satellite-communicator-project","title":"Backlog of Satellite Communicator Project","text":"<p>Design UI/UX.</p> <p>Define product name. </p>"},{"location":"Satellite%20Communicator/Description/","title":"Description","text":""},{"location":"Satellite%20Communicator/Description/#description","title":"Description","text":"<p>This project is mobile application for communication purpose. Messenger app that you can use it when you can't connect to the internet network in emergency situations or ...</p>"},{"location":"Satellite%20Communicator/Description/#technologies","title":"Technologies","text":"<ul> <li>Javascript, Typescript</li> <li>React, React Native</li> <li>Expo</li> </ul> <p>Hodhod_project_sructure</p> <pre><code>    flowchart TB\n        subgraph Internet\n            subgraph Web\n                DataGatheringDashboard[Data Gathering Dashboard]\n            end\n            subgraph Mobile\n                MessengerApp\n            end\n        end\n\n        subgraph Firewall\n            Gateway\n        end\n\n        subgraph WIFI_ReceiverTransceiver\n            subgraph Hardware\n                subgraph Modem\n                    DataGatheringHW\n                    MessengerHW\n                end\n            end\n        end\n\n        subgraph Satellite\n            SatelliteHardware[Satellite Hardware]\n        end\n\n        WIFI_ReceiverTransceiver --RADIO--&gt; Satellite\n        Satellite --RADIO--&gt; HodhodServer\n\n        Internet --REST--&gt; WIFI_ReceiverTransceiver\n\n        Internet --REST--&gt; Gateway\n\n        Gateway --REST--&gt; HodhodServer[Hodhod Server]\n        HodhodServer --REST--&gt; ELKHodhod[(ELK Hodhod)]</code></pre>"},{"location":"Satellite%20Communicator/Description/#sub-project","title":"Sub Project","text":"<ul> <li>MessengerApp (Frontend). Implement via <code>ReactNative(Expo)</code> </li> <li>Modem (Hardware). Implement via <code>STM32F103CT8(Arduino)</code> </li> <li>Hodhod Server (Backend). Implement via <code>DotNetCore</code> </li> </ul>"},{"location":"Satellite%20Communicator/Description/#database","title":"Database","text":"<ul> <li> ElasticSearch</li> </ul> <p>Userflow</p> <pre><code>    stateDiagram-v2\n        state fork_state &lt;&lt;fork&gt;&gt;\n        HodHod --&gt; fork_state\n        fork_state --&gt; Client\n        fork_state --&gt; Server\n        fork_state --&gt; Satellite\n\n        state Client_state &lt;&lt;fork&gt;&gt;\n        Client --&gt; Client_state\n        Client_state --&gt; App\n        Client_state --&gt; Device\n\n\n        App --&gt; Data_Collector\n        App --&gt; Communicator\n\n        state Communicator_state &lt;&lt;fork&gt;&gt;\n        Communicator --&gt; Communicator_state\n        Communicator_state --&gt; Login,Register,Auth\n        Communicator_state --&gt; Communication_over_wifi_to_device\n        Communicator_state --&gt; Save,Edit,ShowStatus_messages\n        Communicator_state --&gt; Create,Edit,Delete,Update_chats\n\n        state Data_Collector_state &lt;&lt;fork&gt;&gt;\n        Data_Collector --&gt; Data_Collector_state\n        Data_Collector_state --&gt; Login,Register,Auth\n        Data_Collector_state --&gt; Communication_over_wifi_to_device\n        Data_Collector_state --&gt; Data_Logger\n        Data_Collector_state --&gt; Setting\n\n        Device --&gt; Communicator_Collector\n        state Communicator_Collector_state &lt;&lt;fork&gt;&gt;\n        Communicator_Collector --&gt; Communicator_Collector_state\n        Communicator_Collector_state --&gt; Connection_to_Sensors\n        Communicator_Collector_state --&gt; Wifi_Setting\n        Communicator_Collector_state --&gt; GPS\n        Communicator_Collector_state --&gt; SD_Card\n        Communicator_Collector_state --&gt; Direct_Communication_to_Satellite\n</code></pre>"},{"location":"Satellite%20Communicator/Description/#feature-list","title":"Feature List","text":"<ol> <li> <p>Authentication</p> <ul> <li>User Managment system for Login, Register,... or any synchronization between services</li> </ul> </li> <li> <p>Communication over wifi</p> <ul> <li>using wifi protocol and http as communication between device and phone</li> </ul> </li> <li> <p>Messenger features</p> <ul> <li>Common messenger features like send simple text or emojis, change personal informations and ...</li> </ul> </li> <li> <p>Change device default setting</p> </li> <li>...</li> </ol>"},{"location":"Satellite%20Communicator/Description/#team","title":"Team","text":"<ul> <li>Mr. Zarei</li> </ul>"},{"location":"Satellite%20Data%20Collector/Backlog/","title":"Backlog","text":""},{"location":"Satellite%20Data%20Collector/Backlog/#backlog-of-satellite-data-collector-project","title":"Backlog of Satellite Data Collector Project","text":"<p>Design UI/UX.</p> <p>Define product name. </p>"},{"location":"Satellite%20Data%20Collector/Description/","title":"Description","text":""},{"location":"Satellite%20Data%20Collector/Description/#description","title":"Description","text":"<p>This project is mobile application for collect data from mobile app. and send to satellite. you can use this application to monitor your logging data and change default settings in place or monitor logged data in any remote place using internet connection.</p>"},{"location":"Satellite%20Data%20Collector/Description/#technologies","title":"Technologies","text":"<ul> <li>Javascript, Typescript</li> <li>React, React Native</li> <li>Expo</li> </ul> <p>Hodhod_project_sructure</p> <pre><code>    flowchart TB\n        subgraph Internet\n            subgraph Web\n                DataGatheringDashboard[Data Gathering Dashboard]\n            end\n            subgraph Mobile\n                MessengerApp\n            end\n        end\n\n        subgraph Firewall\n            Gateway\n        end\n\n        subgraph WIFI_ReceiverTransceiver\n            subgraph Hardware\n                subgraph Modem\n                    DataGatheringHW\n                    MessengerHW\n                end\n            end\n        end\n\n        subgraph Satellite\n            SatelliteHardware[Satellite Hardware]\n        end\n\n        WIFI_ReceiverTransceiver --RADIO--&gt; Satellite\n        Satellite --RADIO--&gt; HodhodServer\n\n        Internet --REST--&gt; WIFI_ReceiverTransceiver\n\n        Internet --REST--&gt; Gateway\n\n        Gateway --REST--&gt; HodhodServer[Hodhod Server]\n        HodhodServer --REST--&gt; ELKHodhod[(ELK Hodhod)]</code></pre>"},{"location":"Satellite%20Data%20Collector/Description/#sub-project","title":"Sub Project","text":"<ul> <li>DataGathering Dashboard (Frontend). Implement via <code>React(Nextjs)</code> </li> <li>Modem (Hardware). Implement via <code>STM32F103CT8(Arduino)</code> </li> <li>Hodhod Server (Backend). Implement via <code>DotNetCore</code> </li> </ul>"},{"location":"Satellite%20Data%20Collector/Description/#database","title":"Database","text":"<ul> <li> ElasticSearch</li> </ul> <p>Userflow</p> <pre><code>    stateDiagram-v2\n        state fork_state &lt;&lt;fork&gt;&gt;\n        HodHod --&gt; fork_state\n        fork_state --&gt; Client\n        fork_state --&gt; Server\n        fork_state --&gt; Satellite\n\n        state Client_state &lt;&lt;fork&gt;&gt;\n        Client --&gt; Client_state\n        Client_state --&gt; App\n        Client_state --&gt; Device\n\n\n        App --&gt; Data_Collector\n        App --&gt; Communicator\n\n        state Communicator_state &lt;&lt;fork&gt;&gt;\n        Communicator --&gt; Communicator_state\n        Communicator_state --&gt; Login,Register,Auth\n        Communicator_state --&gt; Communication_over_wifi_to_device\n        Communicator_state --&gt; Save,Edit,ShowStatus_messages\n        Communicator_state --&gt; Create,Edit,Delete,Update_chats\n\n        state Data_Collector_state &lt;&lt;fork&gt;&gt;\n        Data_Collector --&gt; Data_Collector_state\n        Data_Collector_state --&gt; Login,Register,Auth\n        Data_Collector_state --&gt; Communication_over_wifi_to_device\n        Data_Collector_state --&gt; Data_Logger\n        Data_Collector_state --&gt; Setting\n\n        Device --&gt; Communicator_Collector\n        state Communicator_Collector_state &lt;&lt;fork&gt;&gt;\n        Communicator_Collector --&gt; Communicator_Collector_state\n        Communicator_Collector_state --&gt; Connection_to_Sensors\n        Communicator_Collector_state --&gt; Wifi_Setting\n        Communicator_Collector_state --&gt; GPS\n        Communicator_Collector_state --&gt; SD_Card\n        Communicator_Collector_state --&gt; Direct_Communication_to_Satellite\n</code></pre>"},{"location":"Satellite%20Data%20Collector/Description/#feature-list","title":"Feature List","text":"<ol> <li>Authentication<ul> <li>User Managment system for Login, Register,... or any synchronization between services</li> </ul> </li> <li>Communication over wifi<ul> <li>using wifi protocol and http as communication between device and phone</li> </ul> </li> <li>Data Logging<ul> <li>log data to satellite and user phone in place</li> </ul> </li> <li>Change device default setting</li> <li>...</li> </ol>"},{"location":"Satellite%20Data%20Collector/Description/#team","title":"Team","text":"<ul> <li>Mr. Zarei</li> </ul>"},{"location":"Service%20Log/","title":"log documentation","text":"<p>This documentation provides information about log service which is designed to store error logs from different services in elastic that later can be retrieved.  </p>"},{"location":"Service%20Log/#technologies-used-in-project","title":"Technologies Used in Project","text":"<ul> <li>FastAPI</li> <li>Elasticsearch</li> </ul>"},{"location":"Service%20Log/#getting-started","title":"Getting Started","text":"<p>In order to run the service in local mode use <code>uvicorn main:app --reload</code> command. the project has docker file that uses gunicorn with uvicorn worker</p>"},{"location":"Service%20Log/#general-workflow-of-the-project","title":"General WorkFLow of the Project","text":"<ul> <li>There are three API reference that can be used for working with elastic, one can be used to create new index(right now it is using default index name that is specified in the code and is not adviced to change it!) the other two can be used to save errors in the elatic on the default index(one would get id to store in elastic and the other let elastic auto id generate PN:latter API is suggested!) </li> </ul>"},{"location":"Service%20Log/#project-structure-and-workflow","title":"Project Structure and WorkFlow","text":"<p>The <code>main.py</code> contains all the routes and functions that use below files  util Contains elastic connection information * models* It has two main file: 1. <code>async_elastic.py</code>: This file containt elastic functions that will be used in the project to interact with elastic 1. <code>error_model.py</code>: This file contains model that specifies the error model  </p>"},{"location":"Service%20Log/#general-api-reference","title":"General API Reference","text":"<p>Last Update: 5/21/2023 Check if the service is Runnig: [GET] <code>/</code> to create new index(get index name as json): [POST] <code>/create-index</code> to insert new document with specified id: [POST] <code>/inser-doc-with-id</code> to insert new document(Use this!): [POST] <code>/inser-doc</code> </p>"},{"location":"Streaming/","title":"Socket cluster server and client documentation","text":"<pre><code>  graph LR\n  A[RabbitMQ] --&gt; B[Publisher]\n  B --&gt; C[Socket Server]\n  C --&gt; Client(Web, Mobile)</code></pre> <p>This documentation provides information about socket cluster server and clients(both publisher and subscriber). there is also a README.md file available to this project for quick reference.  </p>"},{"location":"Streaming/#socketcluster-server-and-clientspublisher","title":"SocketCluster server and clients(Publisher)","text":"<p>These three services are  designed in a way to create channel between RabbitMQ and clients so they can have realtime data exchange</p>"},{"location":"Streaming/#technologies-used-in-project","title":"Technologies Used in Project","text":"<ul> <li>SocketCluster</li> <li>Node.js</li> <li>flask</li> <li>Docker</li> </ul>"},{"location":"Streaming/#getting-started","title":"Getting Started","text":"<p>Since the project is using Docker and placed on kubernetes, the images contain all required libraries and dependencies and you just need to have Docker installed(all three services are capable of running in local mode without docker too), however, if you want to run each part separately or outside docker, you need to make sure these items are installed on your machine: 1. Node.js 2. Docker 3. python For flask check the requierments file and install them(inside Venv) for nodejs just type 'npm install'  </p>"},{"location":"Streaming/#general-workflow-of-the-project","title":"General WorkFLow of the Project","text":"<ul> <li> <p>When all services are up and running, you should send a request to publisher(flask) service to create a channel to RabbitMQ service and listen on it for incoming data:   </p> <p>this can be done through <code>/v1/create-rabbit-ch</code>.  </p> </li> <li> <p>Then you need to send request from sub client(s) to publisher(flask) service to create a channel for that client with its clientID (request POST method and send json)</p> <p>this can be done through <code>/v1/create-channel-client</code>. you need to include JSON Body that contains name, email, password  </p> </li> <li>After last two steps the publisher will share Rabbit data via channel to the user that requested it</li> <li>PN: the socketsub service is for test porpuses only and shouldn`t be used in production!</li> </ul>"},{"location":"Streaming/#general-api-reference","title":"General API Reference","text":"<p>Last Update: 3/13/2023 only should be called once in the project startup: [GET] <code>/v1/create-rabbit-ch</code> should be called by client and contains JSON file wiht Client id: [POST] <code>/v1/create-channel-client</code> ONLY SHOULD BE USED IN TEST MODE TO GENRATE FAKE DATA!: [GET] <code>/v1/publish-data-over-ch</code> is a way to make sure publisher(flask) service is up and running and responsive: [GET] <code>/</code> </p>"},{"location":"Streaming/socket-publisher/","title":"socket cluster Publisher","text":"<p>For this service we are using Flask for handling requests and socketcluster-client-python for creating socket object to connect to socket server and publish data and creating channels(sending requests for creating channels both for clients and Rabbit service). in order to access it and view the code or run it change your Directory to <code>./socketpub</code> </p>"},{"location":"Streaming/socket-publisher/#how-socket-client-publisher-works","title":"How socket client publisher works","text":"<p>This part is the trickiest part that does the heavy liftings(creating channels for each client, get data grom rabit and publish it to the client that requested it, using multiThreading to handle multiple request at same time). it contains different files and we describe each one here: - <code>./socketpub/util</code> it has <code>sc.py</code> file that creates a socket objects(take an argument Delay): Delay is the number of seconds that it waits for server to response(it also tries to connect each second meaning if you set Delay to 10 it will try to connect to server 10 times in 10 seconds). <code>socketServerAdd = os.getenv(\"SOCKET_SERVER_ADD\", 'localhost')</code> and <code>socketServerPort = os.getenv(\"SOCKET_SERVER_PORT\", '8000')</code> are server address and port respectively, first check for env variabled(in docker or kuber) if didnt provided(like in local test) use default values. The <code>connect_to_socket_server_multithread</code> function is used to have multiple objects for handling more request, it uses multi threading and has two arguments, Delay and max_connection that will specify number of objects that we need - <code>./socketpub</code> In this directory we have three .py file and one docker file:  </p> <p><code>connection.py</code> Is used to connect to RabbitMQ <code>reciever.py</code> Is used to handle RabbitMQ Events <code>app.py</code> Is the main flask app that contains routes(check the API renference for more information).  </p>"},{"location":"Streaming/socket-publisher/#api-renference","title":"API Renference","text":"<ul> <li>To Check if publisher is working [GET] <code>/</code></li> <li>To create a Channel with clientID name so client can listen on it and publisher send data over it for that client [POST] <code>/v1/create-channel-client</code></li> <li>To tell flask to generate fake data [GET] <code>/v1/publish-data-over-ch</code> TEST ONLY</li> <li>To create a Channel to listen for Rabbit [GET] <code>/v1/create-rabbit-ch</code> DEPRICATED</li> </ul>"},{"location":"Streaming/socket-server/","title":"socket cluster server","text":"<p>For this service we are using SocketCluster and it is Dockerized and fully finctional, we just made some minor changes to fit it to our needs(will be mentioned in this page) in order to access it and view the code or run it change your Directory to <code>./socketserver</code> </p>"},{"location":"Streaming/socket-server/#how-to-use-socket-server","title":"How to use socket server","text":"<p>After running this service you need to create socket object in your clients and send connection request and Handshake(these parts are discussed in details in socket clients section)  </p> <p>PN: there was some problem using the command mentioned in the original documentation for running the server with docker, the way we overcome this problem is by building and running the dockerfile manually using CMD(it is hosted on kuber, so dont need to create DockerCompose). the total number of connection will be printed on every new connection(wont be printed on disconnect!)</p>"},{"location":"Streaming/socket-server/#permissions","title":"permissions","text":"<p>Every client that has access to our server can create a channel or listen to one that already exists, However to publish to a channel the client needs to have auth token and provide it in its request(to get this Token check API Reference below). On every connection will be print on the console so you are sure that handshake was successful. On every disconnection the id of the client will be printed on the console  </p>"},{"location":"Streaming/socket-server/#api-renference","title":"API Renference","text":"<ul> <li>In order to make a socket connection to the server read the clients documents.  </li> <li>To get the Auth token to for publisher [GET] <code>/jwt</code></li> </ul>"},{"location":"Streaming/socket-sub/","title":"socket cluster Client","text":"<p>For this service we are using Nodejs for handling requests and socketcluster-client for creating socket object to connect to socket server and listen on a channel(Wont have privilage to publish data on channel) THIS IS FOR TEST ONLY AND SHOULD BE USED AS SAMPLE CODE TO IMPLEMENT CLIENTS! in order to access it and view the code or run it change your Directory to <code>./socketsub</code> </p>"},{"location":"Streaming/socket-sub/#how-socket-client-sub-works","title":"How socket client sub works","text":"<p>This part is the trickiest part that does the heavy liftings(creating channels for each client, get data grom rabit and publish it to the client that requested it, using multiThreading to handle multiple request at same time). it contains different files and we describe each one here: - <code>./socketsub/util</code> it has <code>sc.js</code> file that creates a socket objects and return it.   - <code>./socketsub</code> In this directory  there is only one .js file:  </p> <p><code>server.js</code> Is used connect ot server and listen on incoming data on channel and print it  </p>"},{"location":"Upload%20Center/","title":"Upload documentation","text":"<p>This documentation provides information about upload center that its goal is to replace ArvanCloud bucket and serve as upload center, Meaning it can recieve files(Images, Videos, ...) and got access for download. PN: Right now there is no restrion on data types and file size.  </p>"},{"location":"Upload%20Center/#technologies-used-in-project","title":"Technologies Used in Project","text":"<ul> <li>Node.js</li> <li>Express.js</li> <li>Mutler</li> <li>Cors</li> <li>Docker</li> </ul>"},{"location":"Upload%20Center/#getting-started","title":"Getting Started","text":"<p>You can use <code>npm server.js</code> or <code>node server.js</code> commands(make sure you are in the same directory as server.js) to run the service in local mode and test, However, the docker image is avaiable and should be used for production mode.  </p>"},{"location":"Upload%20Center/#general-workflow-of-the-project","title":"General WorkFLow of the Project","text":"<ul> <li>There are three api references for uploading files, getting the list of uploaded files and downloading the file(Check API reference part).  </li> </ul>"},{"location":"Upload%20Center/#project-structure-and-workflow","title":"Project Structure and WorkFlow","text":"<p>Different folders in the project will be described here by the order that they receive and proccess the File: middleware this part contains <code>upload.js</code> file that is responsible for configuring multer and saving the file in the fileserver controller this part contains <code>file_upload_controller.js</code> file that is responsible for handling errors and functions that are responsible for serving the routes routes* this part contains <code>routes.js</code> file that is responsible for routes and mthods(POST, Get) and calls<code>file_upload_controller.js</code> methods on the URL  </p>"},{"location":"Upload%20Center/#general-api-reference","title":"General API Reference","text":"<p>Last Update: 5/21/2023 Upload a file: [POST] <code>/upload</code> Get list of stored files with respective links: [GET] <code>/files</code> Download a file: [GET] <code>/files/:name</code> </p>"}]}